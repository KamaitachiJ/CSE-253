{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0.8 # SPLIT% of train, 1 - SPLIT validation\n",
    "BATCH_SIZE = 30 #seq_lenth\n",
    "DROPOUT = 0\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0\n",
    "INPUT_SIZE = 94\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = 94\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0\n",
    "#N_LSTM_CELLS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import PIL\n",
    "from tqdm import tqdm\n",
    "\n",
    "class one_hot_encoder:\n",
    "    def __init__(self, data):\n",
    "        self.classes = set(data)\n",
    "        self.n_classes = len(self.classes)\n",
    "        self.char_to_idx = {ch:i for i, ch in enumerate(self.classes)}\n",
    "        self.idx_to_char = {i:ch for i,ch in zip(xrange(self.n_classes), self.classes)}\n",
    "    \n",
    "    def encode(self, string):\n",
    "        \"\"\" input   string: string to be encoded to one hot encoding\n",
    "            output  encoded: one hot enccoding representation of string\n",
    "        \"\"\"\n",
    "        encoded = np.zeros((len(string), self.n_classes))\n",
    "        for i,s in enumerate(string):\n",
    "            idx = self.char_to_idx[s]\n",
    "            encoded[i, idx] = 1\n",
    "        return encoded\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        temp = [self.idx_to_char[idx] for idx in indices]\n",
    "        return ''.join(temp)\n",
    "    \n",
    "    def check(self):\n",
    "        for i in xrange(self.n_classes):\n",
    "            ch = self.idx_to_char[i]\n",
    "            idx = OHE.char_to_idx[ch]\n",
    "            if i != idx:\n",
    "                print 'OHE function is wrong, idx: %i suppose to be' %i + ch +'but' + ch + 'has idx: %i' %idx\n",
    "            elif i == OHE.n_classes-1:\n",
    "                print 'OHE function correct'\n",
    "\n",
    "class MusicData(Dataset):\n",
    "    def __init__(self, data_set, OHE, transform = None):\n",
    "#         self.images = torch.from_numpy(data_set[:,0])\n",
    "#         self.images = self.images.permute(0, 3, 1, 2)\n",
    "#         self.labels = torch.Tensor(data_set[:,1])\n",
    "        self.data = data_set[:-1]\n",
    "        self.label = data_set[1:]\n",
    "        self.transform = transform\n",
    "        self.OHE = OHE\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x,y = self.data[index], self.label[index]\n",
    "        x = self.OHE.encode(x)\n",
    "        y = self.OHE.char_to_idx[y]\n",
    "        \n",
    "        y = torch.LongTensor([int(y)])\n",
    "        x = torch.Tensor(x)\n",
    "        sample = (x,y)\n",
    "        return sample\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "use_gpu = torch.cuda.is_available()\n",
    "# class batch_generator:\n",
    "#     def __init__(self, batch_size = BATCH_SIZE, n_lstm_cells = N_LSTM_CELLS):\n",
    "#         self.batch_size = batch_size\n",
    "#         self.seq_length = n_lstm_cells\n",
    "#     def gen(self, data, num_samples, OHE):\n",
    "        \n",
    "#         batch_size = self.batch_size\n",
    "#         seq_length = self.seq_length\n",
    "#         while True:\n",
    "#             curr_size = batch_size\n",
    "#             X_batch = np.zeros((curr_size, seq_length, OHE.n_classes))\n",
    "#             y_batch = np.zeros((curr_size, seq_length, OHE.n_classes))\n",
    "#             for i in range(curr_size):\n",
    "#                 idx = np.random.randint(len(data) - seq_length - 1)\n",
    "#                 input_str = data[idx:idx + seq_length]\n",
    "#                 target_str = data[idx + 1:idx + seq_length + 1]\n",
    "#                 X_batch[i, :, :] = OHE.encode(input_str)\n",
    "#                 y_batch[i, :, :] = OHE.encode(target_str)\n",
    "#             yield X_batch, y_batch\n",
    "# class temp_softmax:\n",
    "#     def __init__(self, temp = 1.0):\n",
    "#         self.temp = temp\n",
    "    \n",
    "#     def sample(self, soft_output):\n",
    "#         ''' soft_output: the softmax output of the RNN\n",
    "#         '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in .txt file\n",
    "data = data = open('data/input.txt', 'r').read()\n",
    "total_data_size = len(data)\n",
    "OHE = one_hot_encoder(data)\n",
    "\n",
    "# split into train and validation sets\n",
    "train_data, validation_data = data[:int(SPLIT*total_data_size)], data[int(SPLIT*total_data_size):]\n",
    "train_data_tensor, valid_data_tensor = MusicData(train_data, OHE, transform), MusicData(validation_data, OHE, transform)\n",
    "# train_size, validation_size = len(train_data) - N_LSTM_CELLS + 1, len(validation_data) - N_LSTM_CELLS + 1\n",
    "# batch_gen = batch_generator()\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset = train_data_tensor,\n",
    "    shuffle = False,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 4\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    dataset = valid_data_tensor,\n",
    "    shuffle = False,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, DROPOUT):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout = DROPOUT)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.hidden = self.hidden_init()\n",
    "    \n",
    "    def hidden_init(self):\n",
    "        # check if this needs to be loaded into cuda\n",
    "        if use_gpu:\n",
    "            return (Variable(torch.zeros(self.num_layers, 1, self.hidden_size).cuda()),\n",
    "                    Variable(torch.zeros(self.num_layers, 1, self.hidden_size).cuda()))\n",
    "    \n",
    "    def forward(self, inputs, hidden):\n",
    "        x, new_hidden = self.lstm(inputs, hidden)\n",
    "        x = self.linear(x)\n",
    "        return x, new_hidden\n",
    "\n",
    "def calc_loss_acc(model, data_loader, objective, mode):\n",
    "    num_correct = Variable(torch.cuda.FloatTensor(1).zero_())\n",
    "    loss_temp = 0\n",
    "    total_data = 0\n",
    "    model.eval()\n",
    "    hidden = model.hidden_init()\n",
    "    if mode == 0:\n",
    "        func = 'Calculating Train Loss/Acc'\n",
    "    elif mode == 1:\n",
    "        func = 'Calculating Validation Loss/Acc'\n",
    "\n",
    "    for x, y in tqdm(data_loader, desc = func):\n",
    "        if use_gpu:\n",
    "            x, y = Variable(x.cuda(), volatile = True), Variable(y.cuda(), volatile = True)\n",
    "        output, hidden = model.forward(x, hidden)\n",
    "        _,pred_y = torch.max(output.data, 2)\n",
    "        #y = y.view(-1)\n",
    "        #num_correct += torch.sum(torch.eq(torch.transpose(y,0,1).type(torch.cuda.LongTensor), Variable(pred_y.type(torch.cuda.LongTensor))))\n",
    "        num_correct += torch.sum(torch.eq(y.type(torch.cuda.LongTensor), Variable(pred_y.type(torch.cuda.LongTensor)))).type(torch.cuda.FloatTensor)\n",
    "        loss_temp += objective(output.view(torch.Size((output.size()[0],94))), y.view(-1))*x.size()[0]\n",
    "        total_data += x.size()[0]\n",
    "    return loss_temp/float(total_data), num_correct/float(total_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, objective, lr_decay, epochs = 100, early_stop = 4, verbose = True):\n",
    "    start_time = time.time()\n",
    "    acc_record = {}\n",
    "    loss_record = {}\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    loss_temp = 0\n",
    "    total_data = 0\n",
    "    best_acc = last_acc = 0\n",
    "    hidden = model.hidden_init()\n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    for epoch in xrange(epochs):\n",
    "        if verbose:\n",
    "            print 'epoch %i' %(epoch + 1)\n",
    "        model.train()\n",
    "        #learning_decay.step()\n",
    "        for x,y in tqdm(train_data_loader, desc = 'Training'):\n",
    "            if use_gpu:\n",
    "                x,y = Variable(x.cuda()), Variable(y.cuda())\n",
    "            y = y.view(-1)\n",
    "            # set optimizer parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward prop\n",
    "            outputs, hidden = model.forward(x, hidden)\n",
    "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "            _,pred_y = torch.max(outputs.data,1)\n",
    "            loss = objective(outputs.view(torch.Size((outputs.size()[0],94))), y)\n",
    "\n",
    "            #backward prop\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#             #record batch loss and num_correct\n",
    "#             num_correct += torch.sum(torch.eq(y.type(torch.cuda.LongTensor), Variable(pred_y.type(torch.cuda.LongTensor)))).type(torch.cuda.FloatTensor)\n",
    "#             loss_temp += loss*x.size()[0]\n",
    "#             total_data += x.size()[0]\n",
    "#         train_loss, train_acc = loss_temp/total_data, num_correct/total_data\n",
    "        train_loss, train_acc = calc_loss_acc(model, train_data_loader, objective,0)\n",
    "        valid_loss, valid_acc = calc_loss_acc(model, valid_data_loader, objective,1)\n",
    "        acc_record[epoch] = [train_acc, valid_acc]\n",
    "        loss_record[epoch] = [train_loss, valid_loss]\n",
    "        lr_decay.step(valid_acc.data[0])\n",
    "        if verbose:\n",
    "            print 'train loss: %f \\t valid loss: %f' %(train_loss.data[0], valid_loss.data[0])\n",
    "            print 'train acc: %f \\t valid acc: %f' %(train_acc.data[0], valid_acc.data[0])\n",
    "\n",
    "        if epoch != 0 and last_acc >= valid_acc.data[0]:\n",
    "            rise_epoch +=1\n",
    "            if rise_epoch == early_stop:\n",
    "                if verbose:\n",
    "                    print 'early stop condition met'\n",
    "                    time_elapsed = (time.time() - start_time)\n",
    "                    print 'time elapsed: %i m %f s' %(time_elapsed//60, time_elapsed%60)\n",
    "                return model, best_model, best_acc, loss_record, acc_record, (time.time() - start_time)\n",
    "            last_acc = valid_acc.data[0]\n",
    "        else:\n",
    "            rise_epoch = 0\n",
    "            if valid_acc.data[0] >= best_acc:\n",
    "                best_acc = valid_acc.data[0]\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            last_acc = valid_acc.data[0]\n",
    "            if verbose:\n",
    "                print '-'*80\n",
    "    time_elapsed = (time.time() - start_time)\n",
    "    print 'time elapsed: %i m %f s' %(time_elapsed//60, time_elapsed%60)\n",
    "    return model, best_model, best_acc, loss_record, acc_record, (time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = Model(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, NUM_LAYERS, DROPOUT)\n",
    "optimizer = optim.SGD(model_simple.parameters(), lr=LR, momentum=MOMENTUM, weight_decay = WEIGHT_DECAY, nesterov = True)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "lr_decay = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, \n",
    "                                                      verbose=False, threshold=0.0001, threshold_mode='rel', \n",
    "                                                      cooldown=0, min_lr=0, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:15<00:00, 184.19it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 367.97it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:10<00:00, 346.75it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.507518 \t valid loss: 2.049627\n",
      "train acc: 0.358033 \t valid acc: 0.418676\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:14<00:00, 185.91it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:39<00:00, 352.65it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 359.56it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.173438 \t valid loss: 1.919022\n",
      "train acc: 0.406202 \t valid acc: 0.444091\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 195.10it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 356.54it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 350.31it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.991114 \t valid loss: 1.858465\n",
      "train acc: 0.443924 \t valid acc: 0.457913\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:13<00:00, 188.83it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:36<00:00, 376.84it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 379.52it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.902028 \t valid loss: 1.792182\n",
      "train acc: 0.468075 \t valid acc: 0.474927\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:10<00:00, 197.34it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:36<00:00, 377.30it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 360.93it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.852670 \t valid loss: 1.763737\n",
      "train acc: 0.479842 \t valid acc: 0.486356\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 192.83it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 365.19it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 365.87it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.906114 \t valid loss: 1.766428\n",
      "train acc: 0.475452 \t valid acc: 0.485673\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:10<00:00, 197.84it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 372.48it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 356.15it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.833109 \t valid loss: 1.726653\n",
      "train acc: 0.488366 \t valid acc: 0.494651\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:14<00:00, 186.71it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:39<00:00, 355.40it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 358.58it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.793496 \t valid loss: 1.735198\n",
      "train acc: 0.504267 \t valid acc: 0.498034\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:07<00:00, 204.31it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 361.05it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 352.71it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.800283 \t valid loss: 1.759805\n",
      "train acc: 0.512495 \t valid acc: 0.505964\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:12<00:00, 192.49it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 368.63it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 361.38it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.790205 \t valid loss: 1.686666\n",
      "train acc: 0.509335 \t valid acc: 0.514327\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:12<00:00, 192.58it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 373.29it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 361.24it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.775051 \t valid loss: 1.725933\n",
      "train acc: 0.516483 \t valid acc: 0.506368\n",
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 193.32it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:39<00:00, 353.65it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 354.41it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.765592 \t valid loss: 1.724273\n",
      "train acc: 0.514866 \t valid acc: 0.506118\n",
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 194.52it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 371.85it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 380.45it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.755337 \t valid loss: 1.802545\n",
      "train acc: 0.522320 \t valid acc: 0.498467\n",
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:12<00:00, 190.27it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:39<00:00, 348.49it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 367.23it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.473040 \t valid loss: 1.578752\n",
      "train acc: 0.584914 \t valid acc: 0.547508\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:10<00:00, 197.34it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:36<00:00, 376.46it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 355.98it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.428508 \t valid loss: 1.575657\n",
      "train acc: 0.595204 \t valid acc: 0.549728\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:09<00:00, 199.15it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 362.82it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 357.49it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.400652 \t valid loss: 1.574525\n",
      "train acc: 0.601952 \t valid acc: 0.550161\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:10<00:00, 196.06it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 368.18it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 362.04it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.384072 \t valid loss: 1.577092\n",
      "train acc: 0.605703 \t valid acc: 0.550517\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 195.36it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 374.56it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 369.63it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.373944 \t valid loss: 1.583274\n",
      "train acc: 0.607998 \t valid acc: 0.551372\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:12<00:00, 191.51it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 360.35it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 357.87it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.367258 \t valid loss: 1.586430\n",
      "train acc: 0.610031 \t valid acc: 0.551497\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 193.28it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 361.66it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 364.81it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.361976 \t valid loss: 1.584098\n",
      "train acc: 0.611405 \t valid acc: 0.551805\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 193.03it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 371.28it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 366.81it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.358769 \t valid loss: 1.586380\n",
      "train acc: 0.612249 \t valid acc: 0.552256\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 194.16it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 373.25it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 351.29it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.356050 \t valid loss: 1.588365\n",
      "train acc: 0.612948 \t valid acc: 0.551545\n",
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:14<00:00, 185.61it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 359.08it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 357.05it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.353212 \t valid loss: 1.592663\n",
      "train acc: 0.613794 \t valid acc: 0.551718\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:12<00:00, 190.34it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 362.59it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 358.67it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.348911 \t valid loss: 1.598841\n",
      "train acc: 0.615072 \t valid acc: 0.551103\n",
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:09<00:00, 198.94it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:36<00:00, 378.04it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 354.51it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.200214 \t valid loss: 1.531384\n",
      "train acc: 0.643147 \t valid acc: 0.564272\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:11<00:00, 193.52it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 358.29it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 356.13it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.182547 \t valid loss: 1.533508\n",
      "train acc: 0.647073 \t valid acc: 0.563993\n",
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:13<00:00, 189.81it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 358.87it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 365.08it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.172287 \t valid loss: 1.536375\n",
      "train acc: 0.649546 \t valid acc: 0.563522\n",
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:10<00:00, 196.98it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 360.41it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 366.45it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.164389 \t valid loss: 1.538402\n",
      "train acc: 0.651552 \t valid acc: 0.563512\n",
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:12<00:00, 190.56it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:39<00:00, 348.99it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 376.21it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.103674 \t valid loss: 1.511774\n",
      "train acc: 0.666468 \t valid acc: 0.566780\n",
      "--------------------------------------------------------------------------------\n",
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:08<00:00, 201.13it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:37<00:00, 366.29it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 368.42it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.088921 \t valid loss: 1.507270\n",
      "train acc: 0.669873 \t valid acc: 0.566579\n",
      "epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:08<00:00, 201.08it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:36<00:00, 375.93it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 367.98it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.083347 \t valid loss: 1.506351\n",
      "train acc: 0.671353 \t valid acc: 0.566559\n",
      "epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:14<00:00, 185.81it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 355.98it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 371.40it/s]\n",
      "Training:   0%|          | 0/13872 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.080388 \t valid loss: 1.505742\n",
      "train acc: 0.672031 \t valid acc: 0.566348\n",
      "epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 13872/13872 [01:12<00:00, 190.32it/s]\n",
      "Calculating Train Loss/Acc: 100%|██████████| 13872/13872 [00:38<00:00, 361.70it/s]\n",
      "Calculating Validation Loss/Acc: 100%|██████████| 3468/3468 [00:09<00:00, 354.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.079710 \t valid loss: 1.505792\n",
      "train acc: 0.672118 \t valid acc: 0.566281\n",
      "early stop condition met\n",
      "time elapsed: 65 m 42.610443 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, best_model, best_acc, loss_record, acc_record, _ = train(model_simple, optimizer, objective, lr_decay, \n",
    "                                                                epochs = 100, early_stop = 4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence2(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prime_str='$', predict_len=100, temperature=0.5):\n",
    "    hidden = model.init_hidden(1)\n",
    "    prime_input = prepare_sequence2(prime_str*1, letter2int)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = model(prime_input[p], hidden)\n",
    "    inp = autograd.Variable(prime_input.cuda())\n",
    "    inp = inp.view(1,-1)\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        # return top_i\n",
    "        # Add predicted character to string and use as next input\n",
    "        temp = int2letter[top_i[0]]\n",
    "        if temp==\"$\":\n",
    "            break\n",
    "        predicted += temp\n",
    "        inp = autograd.Variable(prepare_sequence2(temp, letter2int).cuda())\n",
    "        inp = inp.view(1,-1)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = generate(model, prime_str='$', predict_len=1000, temperature=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
